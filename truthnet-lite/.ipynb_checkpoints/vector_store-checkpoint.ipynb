{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9bb318-55d7-4fda-906c-cb25834d5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b550f0-8323-43ac-bce9-aca8ab41b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ca5560-82b4-4b55-9453-c6fbb84598be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_doc(doc_id, text, metadata):\n",
    "    vector = model.encode(text).tolist()\n",
    "    client.upsert(\n",
    "        collection_name=\"documents\",\n",
    "        points=[{\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"vector\": vector,\n",
    "            \"payload\": {**metadata, \"text\": text}\n",
    "        }]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72dd8786-b699-45ca-a6d7-5569cea122fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_context(query, top_k=3):\n",
    "    vector = model.encode(query).tolist()\n",
    "    return client.search(\"documents\", query_vector=vector, limit=top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effffdd0-bf41-4134-9fea-2109c8afe77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert_doc(\"doc1\", \"Tesla stated in Q2 2023 that margins were under pressure.\", {\"source\": \"10Q_Q2_2023\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e4c64-96ce-40db-ba6f-324b314a1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./parsed_script.json\", \"r\") as file:\n",
    "    movie_dialogues = json.load(file)\n",
    "\n",
    "#print(movie_dialogues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cb12dc-14e2-4b18-8763-560c997480a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting documents: 100%|███████████████████████████████████████████████████████████| 155/155 [00:11<00:00, 13.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for row in tqdm(movie_dialogues, desc=\"Inserting documents\"):\n",
    "    insert_doc(row[\"doc_id\"], row[\"text\"], {\"source\": row[\"source\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2c8ff-84b9-4dac-af54-4f358410a58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f57fbc1-5876-4499-a92f-d5b8018fa949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, contexts):\n",
    "    context_text = \"\\n\".join(f\"{c.payload['text']} [source: {c.payload['source']}]\" for c in contexts)\n",
    "    return f\"\"\"\n",
    "System: Use only the facts below to answer. If unsure, say 'I don't know.'\n",
    "Facts:\n",
    "{context_text}\n",
    "User: {query}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b177e1-aea4-4df9-9739-7f1e1d4e7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI(api_key=\"you api key\")\n",
    "# add comment for key\n",
    "def query_llm(prompt):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83b22a8-2583-4611-a876-62819882cb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akank\\AppData\\Local\\Temp\\ipykernel_34172\\3558304798.py:3: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  return client.search(\"documents\", query_vector=vector, limit=top_k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla stated in Q2 2023 that margins were under pressure.\n"
     ]
    }
   ],
   "source": [
    "llm_input = \"What did Tesla say about Q2?\"\n",
    "contexts = search_context(llm_input)\n",
    "prompt = build_prompt(llm_input, contexts) # this is a RAG query\n",
    "# prompt = built_prompt(llm_input, []) # this is a non RAG query\n",
    "print(query_llm(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6772b3b-5785-469d-8cbe-8e0bff610cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(query_llm(\"Tell me a good joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf87e8f-e120-4863-9f93-072a222fa810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nli = pipeline(\"text-classification\", model=\"microsoft/deberta-large-mnli\")\n",
    "\n",
    "def verify_claim(claim, context):\n",
    "    result = nli(f\"{claim} </s> {context}\")\n",
    "    return result[0]['label']  # Should be 'ENTAILMENT' if valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d2fc1cc-6368-4aa5-96d8-aa3265f63826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRADICTION\n"
     ]
    }
   ],
   "source": [
    "claim = \"Tesla promised 30% margin in Q2\"\n",
    "context = \"Tesla said margins were under pressure in Q2.\"\n",
    "print(verify_claim(claim, context))  # EXPECTED: 'CONTRADICTION' or 'NEUTRAL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56bcd5c0-4c64-4d9b-afa5-7139532fd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_response(claim, contexts):\n",
    "    verify_result = [verify_claim(claim, c.payload[\"text\"]) for c in contexts]\n",
    "    support = sum(1 for r in verify_result if r == \"ENTAILMENT\")\n",
    "    contradiction = sum(1 for r in verify_result if r == \"CONTRADICTION\")\n",
    "    return {\n",
    "        \"supported\": support,\n",
    "        \"contradicted\": contradiction,\n",
    "        \"hallucination_score\": contradiction / (support + 1)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a097a351-931b-4fe4-a734-ae32a2a20c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fallback_handler(score_data):\n",
    "    if score_data['hallucination_score'] > 0.5:\n",
    "        return \"⚠️ Potential hallucination. Would you like to rephrase?\"\n",
    "    return \"✅ Looks good.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77b3c2dc-7a4d-41a7-a259-5213044a14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_response(response, contexts):\n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"sources\": [c.payload[\"source\"] for c in contexts],\n",
    "        \"model_version\": \"gpt-3.5-turbo\",\n",
    "        \"verified\": True\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b046ae17-00b1-4fde-8252-d72e9b3ab975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akank\\AppData\\Local\\Temp\\ipykernel_34172\\3558304798.py:3: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  return client.search(\"documents\", query_vector=vector, limit=top_k)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Who played finger football with Tony Stark?\"\n",
    "contexts_list = search_context(prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc3132e-8556-4859-afa0-e950d0bea64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpt_claim = query_llm(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af47accc-c9b0-4be5-90d6-67a077ac91df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supported': 0, 'contradicted': 3, 'hallucination_score': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'⚠️ Potential hallucination. Would you like to rephrase?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = score_response(gpt_claim, contexts_list)\n",
    "print(score)\n",
    "fallback_handler(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbf6250d-26b4-4b4e-a895-e69519755a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truthnet_query(user_input):\n",
    "    contexts = search_context(user_input) # create another version for non RAG, comment this line \n",
    "    prompt = build_prompt(user_input, contexts) # check for hallucination, replace contexts with [] \n",
    "    answer = query_llm(prompt)\n",
    "    score = score_response(answer, contexts)\n",
    "    trace = tag_response(answer, contexts)\n",
    "    fallback_msg = fallback_handler(score)\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"score\": score,\n",
    "        \"trace\": trace,\n",
    "        \"fallback\": fallback_msg\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33203140-c6c6-48d7-b849-d291efc9c440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[{'question_1': 'What game are Tony Stark and Nebula playing aboard the Benatar?'}, {'question_2': 'What advice does Clint Barton give Lila about using three fingers while shooting an arrow?'}, {'question_3': 'What does Clint Barton say just before Lila disappears?'}, {'question_4': 'What does Tony Stark record in his helmet for Pepper while stranded in space?'}, {'question_5': 'What line does Tony say after finishing his recording and preparing to drift off?'}, {'question_6': 'How does Tony react when he sees Rocket for the first time?'}, {'question_7': \"What is Thanos' answer when Nebula asks what he would do after completing his plan?\"}, {'question_8': 'Who suggests using the Infinity Stones to bring everyone back?'}, {'question_9': 'What does Thor say after beheading Thanos?'}, {'question_10': \"What does Natasha say when asked how she's handling an underwater earthquake?\"}, {'question_11': 'What does Steve Rogers say is still out there, despite the state of the world?'}, {'question_12': 'What joke does Tony Stark make about the time heist plan?'}, {'question_13': 'What phrase does Morgan Stark use to say how much she loves Tony?'}, {'question_14': 'What are the names of the six Infinity Stones shown on the holo-board?'}, {'question_15': 'What title is shown after Thor kills Thanos and the screen fades to black?'}, {'question_16': 'What does Smart Hulk say about combining Bruce and Hulk?'}, {'question_17': 'What does Rocket call Thor when he sees his condition in New Asgard?'}, {'question_18': 'What does Valkyrie say about Thorâ€™s visits to New Asgard?'}, {'question_19': 'What does Clint Barton bring back as proof from the time test?'}, {'question_20': 'What does Tony Stark say when the time travel simulation succeeds?'}, {'question_21': 'What insult does Thor shout at NoobMaster69?'}, {'question_22': \"What does Steve Rogers say about the name 'Avengers' after the snap?\"}, {'question_23': 'What condition are Nebula and Rocket in when they find Tony in space?'}, {'question_24': 'What does Natasha say when she sees Scott Lang on the front gate camera?'}, {'question_25': 'What nickname does Rhodey give Scott Lang during the taco scene?'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"questions.json\", \"r\") as file:\n",
    "    questions = json.load(file)\n",
    "print(type(questions))\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f90d67-cb6f-41c9-a802-0658f1e4082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]C:\\Users\\akank\\AppData\\Local\\Temp\\ipykernel_34172\\3558304798.py:3: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  return client.search(\"documents\", query_vector=vector, limit=top_k)\n",
      " 32%|██████████████████████████▌                                                        | 8/25 [05:55<16:54, 59.66s/it]"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for i in tqdm(range(len(questions))):\n",
    "    row = questions[int(i)]  # force i to be plain int\n",
    "    key = f\"question_{int(i) + 1}\"  # readable key name\n",
    "    question = row[key]\n",
    "    #print(f\"processing {key}\")\n",
    "    results[key] = truthnet_query(question)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019aa94c-30a3-40da-8eca-f2e413eb2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e1073-2d5e-4f16-9659-bd9f72d50ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
